{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Points"
      ],
      "metadata": {
        "id": "c3OekwlMZ9jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Backpropagation chain-rule: https://drive.google.com/file/d/1tUJUn0EJN8oOXlsWF2OiN_ZfWUUc0y-G/view?usp=sharing\n",
        "\n",
        "- For every operation we do with our tensors, PyTorch will create a graph for us, where at each node we apply a operation (function), which then gives us an output.\n",
        "- At these nodes we can create local gradients and use them later in the chain rule to get the final gradient.\n",
        "- At the very end of all our operations, we want to calculate a loss function - we want to calculate the gradient of the loss w.r.t our parameter x from the beginning.\n",
        "\n",
        "  https://drive.google.com/file/d/1Q1UciIHYq6eyLxt91N7q01h7nq4CXrbG/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "IpB6GvMvT5Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole concept of backpropagation consists of three steps:\n",
        "  - Forward pass: compute loss\n",
        "  - Compute local gradients\n",
        "  - Backward pass: compute dLoss/dWeights using the chain rule\n",
        "\n",
        "Here is a concrete example, using linear regression:\n",
        "  - Setup: https://drive.google.com/file/d/1-rSR2uqkcoJMFqnOBfWu3UBW91GgoFMQ/view?usp=sharing\n",
        "  - 3-step process: https://drive.google.com/file/d/1uIUaKPeEb1p_DRaxLN4nw_dlPJ8oOyuB/view?usp=share_link\n",
        "  \n",
        "Here is a numerical example:\n",
        "  - Forward pass: https://drive.google.com/file/d/1kPpteFPz5gJjfcmNsLpUawwiAgyopP1Q/view?usp=sharing\n",
        "  - Backward pass: https://drive.google.com/file/d/1W6DGUAbFQncCXOfejPoVW5jI2TbFbtDn/view?usp=share_link\n",
        "  \n"
      ],
      "metadata": {
        "id": "OoXAAnJAVEjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical Example using PyTorch"
      ],
      "metadata": {
        "id": "ZoM3xQOpaC1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "NeS5MydYY3Zu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad = True)\n",
        "\n",
        "# do forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw9bsGqkZQ2J",
        "outputId": "12fce99d-e1b4-4ce6-897a-1afc0cb296d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we want to do the backward pass\n",
        "# PyTorch will automatically compute the local gradients and backward pass for us\n",
        "\n",
        "# we just need to call .backward() and then 'w' has its .grad() attribute\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZmWs1h0ZSrR",
        "outputId": "ff286737-ef0a-4d26-8785-79a1953de7fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update our weights and do the next forward and backward passes (a few iterations)"
      ],
      "metadata": {
        "id": "WNJ45fo-Zwlx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}