{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XksnoB98I9Ur"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-class neural network\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # no softmax at the end\n",
        "    return out"
      ],
      "metadata": {
        "id": "PvPGgRWgJUzD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss() # this automatically applies softmax\n",
        "print(model)\n",
        "print(criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxEEas5xJcf2",
        "outputId": "28b5a09a-7880-4229-c864-215f978fcea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (linear1): Linear(in_features=784, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n",
            "CrossEntropyLoss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary-classification neural network\n",
        "class NeuralNet1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet1, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear1(x)\n",
        "    output = self.relu(output)\n",
        "    output = self.linear2(output)\n",
        "    output = torch.sigmoid(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "IJEgGqjXLVjR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we use the Binary Cross-Entropy Loss (BCE Loss) instead\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss() # this automatically applies softmax\n",
        "print(model)\n",
        "print(criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFj1pE3LMeOX",
        "outputId": "16e1647d-26c9-4ab1-a764-fc562a4e4b64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet1(\n",
            "  (linear1): Linear(in_features=784, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n",
            "BCELoss()\n"
          ]
        }
      ]
    }
  ]
}